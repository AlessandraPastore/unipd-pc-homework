\section{Trivial parallelization}\label{trivial_parallelization}

Knowing that in general join times after the parallel execution of a given cycle can be very noticeable, it seems a good choice to start parallelizing from the most external cycle «for \(h\)» (\cref{alg:for-h} of \cref{alg:sequential}).

Unfortunately, a dependency analysis shows us that to execute the «for \(h\)»  in parallel, there are some dependencies. One can clearly see that the execution of round \(h=2\) needs to know from round \(h=1\) the row \(1\) and the column \(1\). Continuing the dependencies' analysis, it is noticeable that the cell \((1,1)\) needs to be accessed for the execution of those two row and column, but its value in the matrix \(d\) remains \(0\) throughout the entirety of the algorithm, unlike in the matrix \(pred\) where it can be updated at every iteration of \( i\), as shown in the \cref{fig:data-dependencies-1}.
For the execution of round \(h=3\) it is needed the cell \((2,2)\), row \(2\) and column \(2\) from round \(h=2\), as shown in the \cref{fig:data-dependencies-2}.

The total analysis of the dependencies of the most external loop «for \(h\)», as shown in \cref{fig:data-dependency-external-loop}, shows that paralleling this loop in a simple manner is impossible, but since the execution of loops \(i\) and \(j\) can be done in any order the parallelization of the algorithm will focus on that particular aspect~\cite{rucci}.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/data_dependencies_1}
        \caption{Data dependencies in Floyd algorithm when \(h=2\): the output of the execution of the round \(h=1\), of row \(1\) and column \(1\), is needed. For row and column execution, it's necessary to know the self-dependent cell \((1,1)\), that is always \(0\) in \(d\) and initialized as \(1\) in \(pred\).}
        \label{fig:data-dependencies-1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/data_dependencies_2}
        \caption{Data dependencies in Floyd algorithm when \(h=3\): the output of the execution of the round \(h=2\), of row \(2\) and column \(2\), is needed. For row and column execution, it's necessary to know the self-dependent cell \((2,2)\), that is always \(0\) in \(d\) and initialized as \(2\) in \(pred\).}
        \label{fig:data-dependencies-2}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/data_dependencies_3}
        \caption{Data dependencies in Floyd algorithm: For each \(h+1\), the output of the execution of the round \(h\), of row \(h\) and column \(h\), is needed. For row and column execution, it's necessary to know the self-dependent cell \((h,h)\), that is always \(0\) in \(d\) and initialized as \(h\) in \(pred\).}
        \label{fig:data-dependencies-3}
    \end{subfigure}
    \caption{Data dependency in Floyd algorithm for the execution of each instance of the external for loop. In dark green the self-dependent cell \((h,h)\) which have no data requirements and should be executed before the light green cells of the row \(h\) and column \(h\). Notice that is always \(0\) in \(d\) and initialized as \(h\) in \(pred\) and therefore only the light-green dependency exists.}
    \label{fig:data-dependency-external-loop}
\end{figure}

As mentioned and proved by~\cite{rucci}, it is possible to parallelize internal cycles without any problems. 
Let's start with the parallelization of  the intermediate cycle «for \(i\)» (\cref{alg:for-i} of \cref{alg:sequential}) that on the other hand seems quite possible, as there are no dependencies with respect to other previous or subsequent cycles.
This parallelization, however, exploits the maximum \(p\) thread, and it is not a problem if \(n \geq p\), but it becomes a problem if \(p \gg n\).

The new performance is \(\displaystyle O\left(\frac{n^3}{p}\right)\) plus join times, which are valued \(n\times n\).
The main problem with this implementation is the join times, which are too high.

In a similar way it's possible parallelize the «for \(j\)» (\cref{alg:for-j} of \cref{alg:sequential}) but again, the problem resides in the join time after parallelization, which becomes \(n^3\).

\FloatBarrier
