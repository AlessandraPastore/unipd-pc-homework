\section{Trivial parallelization}\label{trivial_parallelization}

Knowing that in general, synchronisation times after parallel execution of a given cycle can be very, very noticeable, which is why it is good to start parallelising from the most external cycle «for \(h\)».

Analysing the dependencies of the most external loop «for \(h\)», as shown in \cref{fig:data-dependency-external-loop}, we note that parallelling this loop in a simple manner is impossible.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/data_dependencies_1}
        \caption{Data dependencies in Floyd algorithm when \(h=1\). For execute row \(1\) and column \(1\) we need to know the cell \((1,1)\) which, being self-dependent, can be executed first}
        \label{fig:data-dependencies-1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/data_dependencies_2}
        \caption{Data dependencies in Floyd algorithm when \(h=2\). For execute row \(2\) and column \(2\) we need to know the cell \((2,2)\) which, being self-dependent, can be executed first}
        \label{fig:data-dependencies-2}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{media/data_dependencies_3}
        \caption{Data dependencies in Floyd algorithm: For each \(h\) for execute row \(h\) and column \(h\) we need to know the cell \((h,h)\) which, being self-dependent, can be executed first}
        \label{fig:data-dependencies-3}
    \end{subfigure}
    \caption{Data dependency in Floyd algorithm for the execution of each instance of the external for loop. In dark green the self-dependent cell \((h,h)\) which have no data requirements and must be  executed before the light green cells of the \((i,h)\) and \((h,j)\).}
    \label{fig:data-dependency-external-loop}
\end{figure}

Parallelization of the intermediate cycle «for \(i\)» on the other hand seems possible, as there are no dependencies with respect to other previous or subsequent cycles.
This parallelization, however, exploits the maximum \(i\) thread.
Which in the case of machines with numerous threads \(p \gg n\) could be a waste, then \(p\) the number of threads the performance is \(\displaystyle O\left(\frac{n^3}{p}\right)\) plus synchronisation times, which are \(n\times n\).
The main problem with this implementation is the synchronisation times, which are too high.




% parallelizzazione "stupida" quindi parallelizzanzo uno alla volta i 3 cicli e di quanto è inefficenze questa cosa per via di tempi si syncr tra i vari thread

%

